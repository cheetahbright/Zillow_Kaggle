{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_columns = 70\n",
    "pd.options.display.max_rows = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prop.shape\n",
    "good_import_cols = pd.Series(range(0,57))\n",
    "#good_import_cols = good_import_cols.drop([22,32,34,49,55])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\board\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2723: DtypeWarning: Columns (22,32,34,49,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train_df1 = pd.read_csv(\"train_2016.csv\", parse_dates=[\"transactiondate\"])\n",
    "prop = pd.read_csv(\"properties_2016.csv\") #, usecols=good_import_cols)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "C:\\Users\\board\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2723: DtypeWarning: Columns (22,32,34,49,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
    "  interactivity=interactivity, compiler=compiler, result=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>architecturalstyletypeid</td>\n",
       "      <td>2979156</td>\n",
       "      <td>0.997970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basementsqft</td>\n",
       "      <td>2983589</td>\n",
       "      <td>0.999455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>buildingclasstypeid</td>\n",
       "      <td>2972588</td>\n",
       "      <td>0.995769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>decktypeid</td>\n",
       "      <td>2968121</td>\n",
       "      <td>0.994273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>finishedfloor1squarefeet</td>\n",
       "      <td>2782500</td>\n",
       "      <td>0.932093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>finishedsquarefeet13</td>\n",
       "      <td>2977545</td>\n",
       "      <td>0.997430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>finishedsquarefeet15</td>\n",
       "      <td>2794419</td>\n",
       "      <td>0.936086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>finishedsquarefeet50</td>\n",
       "      <td>2782500</td>\n",
       "      <td>0.932093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>finishedsquarefeet6</td>\n",
       "      <td>2963216</td>\n",
       "      <td>0.992630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fireplacecnt</td>\n",
       "      <td>2672580</td>\n",
       "      <td>0.895272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>hashottuborspa</td>\n",
       "      <td>2916203</td>\n",
       "      <td>0.976881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>poolcnt</td>\n",
       "      <td>2467683</td>\n",
       "      <td>0.826634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>poolsizesum</td>\n",
       "      <td>2957257</td>\n",
       "      <td>0.990634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>pooltypeid10</td>\n",
       "      <td>2948278</td>\n",
       "      <td>0.987626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>pooltypeid2</td>\n",
       "      <td>2953142</td>\n",
       "      <td>0.989255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>pooltypeid7</td>\n",
       "      <td>2499758</td>\n",
       "      <td>0.837379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>storytypeid</td>\n",
       "      <td>2983593</td>\n",
       "      <td>0.999456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>threequarterbathnbr</td>\n",
       "      <td>2673586</td>\n",
       "      <td>0.895609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>typeconstructiontypeid</td>\n",
       "      <td>2978470</td>\n",
       "      <td>0.997740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>yardbuildingsqft17</td>\n",
       "      <td>2904862</td>\n",
       "      <td>0.973082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>yardbuildingsqft26</td>\n",
       "      <td>2982570</td>\n",
       "      <td>0.999113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>numberofstories</td>\n",
       "      <td>2303148</td>\n",
       "      <td>0.771518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>fireplaceflag</td>\n",
       "      <td>2980054</td>\n",
       "      <td>0.998270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>taxdelinquencyflag</td>\n",
       "      <td>2928755</td>\n",
       "      <td>0.981086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>taxdelinquencyyear</td>\n",
       "      <td>2928753</td>\n",
       "      <td>0.981085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 column_name  missing_count  missing_ratio\n",
       "2   architecturalstyletypeid        2979156       0.997970\n",
       "3               basementsqft        2983589       0.999455\n",
       "6        buildingclasstypeid        2972588       0.995769\n",
       "9                 decktypeid        2968121       0.994273\n",
       "10  finishedfloor1squarefeet        2782500       0.932093\n",
       "13      finishedsquarefeet13        2977545       0.997430\n",
       "14      finishedsquarefeet15        2794419       0.936086\n",
       "15      finishedsquarefeet50        2782500       0.932093\n",
       "16       finishedsquarefeet6        2963216       0.992630\n",
       "18              fireplacecnt        2672580       0.895272\n",
       "22            hashottuborspa        2916203       0.976881\n",
       "27                   poolcnt        2467683       0.826634\n",
       "28               poolsizesum        2957257       0.990634\n",
       "29              pooltypeid10        2948278       0.987626\n",
       "30               pooltypeid2        2953142       0.989255\n",
       "31               pooltypeid7        2499758       0.837379\n",
       "41               storytypeid        2983593       0.999456\n",
       "42       threequarterbathnbr        2673586       0.895609\n",
       "43    typeconstructiontypeid        2978470       0.997740\n",
       "45        yardbuildingsqft17        2904862       0.973082\n",
       "46        yardbuildingsqft26        2982570       0.999113\n",
       "48           numberofstories        2303148       0.771518\n",
       "49             fireplaceflag        2980054       0.998270\n",
       "55        taxdelinquencyflag        2928755       0.981086\n",
       "56        taxdelinquencyyear        2928753       0.981085"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_df = prop.isnull().sum(axis=0).reset_index()\n",
    "missing_df.columns = ['column_name', 'missing_count']\n",
    "missing_df = missing_df.loc[missing_df['missing_count']>0]\n",
    "\n",
    "missing_df['missing_ratio'] = missing_df['missing_count'] / prop.shape[0]\n",
    "missing_df.loc[missing_df['missing_ratio']>0.75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df1.merge(prop, on='parcelid', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_values = train_df.mean(axis=0)\n",
    "train_df_new = train_df.fillna(mean_values, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['transaction_month'] = train_df['transactiondate'].dt.month\n",
    "mean_values = train_df.mean(axis=0)\n",
    "train_df_new = train_df.fillna(mean_values, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transaction_month\n",
       "1      6574\n",
       "2      6401\n",
       "3      8752\n",
       "4      9407\n",
       "5     10056\n",
       "6     10968\n",
       "7      9984\n",
       "8     10510\n",
       "9      9597\n",
       "10     4991\n",
       "11     1829\n",
       "12     1742\n",
       "Name: logerror, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby(by=['transaction_month']).logerror.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['parcelid', 'transactiondate', 'hashottuborspa',\n",
       "       'propertycountylandusecode', 'propertyzoningdesc', 'fireplaceflag',\n",
       "       'taxdelinquencyflag', 'transaction_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_drop = train_df.dtypes[train_df.dtypes != \"float64\"].index\n",
    "train_df.dtypes[train_df.dtypes != \"float64\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [count, val]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df2 = train_df.drop(['propertycountylandusecode', 'propertyzoningdesc', 'taxdelinquencyflag', 'hashottuborspa','fireplaceflag' ], axis = 1)\n",
    "missing_df2 = train_df2.isnull().sum(axis=0).reset_index()\n",
    "missing_df2.columns = ['count', 'val']\n",
    "missing_df2[missing_df2['val'] > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_df2.to_csv(\"semi_clean_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_cols = train_df.drop(cols_to_drop, axis = 1).columns\n",
    "train_df_scale = MinMaxScaler().fit_transform(train_df.drop(['parcelid', 'transactiondate', 'hashottuborspa',\n",
    "       'propertycountylandusecode', 'propertyzoningdesc', 'fireplaceflag',\n",
    "       'taxdelinquencyflag', 'transaction_month', 'logerror'],axis = 1))\n",
    "#train_df_scale = MinMaxScaler().fit_transform(train_df.drop(cols_to_drop, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_y = train_df['logerror']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model  \n",
    "from keras.layers import Dense, Activation, Dropout, Input, BatchNormalization \n",
    "from keras import losses \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.optimizers import SGD\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def R_square(y_true, y_pred):\n",
    "    SS_res = K.pow((y_true - y_pred),2)\n",
    "    SS_tot = K.pow((y_true - K.mean(y_true)),2)\n",
    "    return (1-(SS_res/SS_tot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(learning_rate = 0.005, decay_rate = 0.001, momentum1 = 0.8, init1 = \"uniform\", act1 = \"relu\",\n",
    "                act2 = \"tanh\"): \n",
    "    model = Sequential() \n",
    "    model.add(Dense(52, input_dim = train_df_scale.shape[1], kernel_initializer = init1, activation=act1))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(100,kernel_initializer = init1, activation = act1))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(26, kernel_initializer = init1, activation = act2))\n",
    "    model.add(Dense(4, kernel_initializer = init1, activation = act2))\n",
    "    model.add(Dense(1, kernel_initializer= \"normal\", activation='linear'))\n",
    "    \n",
    "    sgd = SGD(lr = learning_rate, momentum = momentum1, decay = decay_rate, nesterov = False )\n",
    "    model.compile(loss = 'mae', optimizer = sgd, metric = [R_square])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath=\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='mae', verbose=1, save_best_only=True, mode='max')\n",
    "stopping= EarlyStopping(monitor = 'loss', patience  = 3, mode = \"max\")\n",
    "callbacks_list = [stopping]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "model.fit(train_df_scale, train_y, validation_split = val_per, epochs = epochs, batch_size = batch_size1, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\board\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2250: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72648 samples, validate on 18163 samples\n",
      "Epoch 1/20\n",
      "72648/72648 [==============================] - 4s - loss: 0.0698 - val_loss: 0.0667\n",
      "Epoch 2/20\n",
      "72648/72648 [==============================] - 4s - loss: 0.0697 - val_loss: 0.0670\n",
      "Epoch 3/20\n",
      "72648/72648 [==============================] - 4s - loss: 0.0697 - val_loss: 0.0665\n",
      "Epoch 4/20\n",
      "72648/72648 [==============================] - 4s - loss: 0.0697 - val_loss: 0.0666\n",
      "Epoch 5/20\n",
      "72648/72648 [==============================] - 4s - loss: 0.0696 - val_loss: 0.0666\n"
     ]
    }
   ],
   "source": [
    "model2 = create_model().fit(train_df_scale, train_y, epochs = 20, validation_split = 0.2, batch_size = 30, \n",
    "                            callbacks = callbacks_list, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n"
     ]
    }
   ],
   "source": [
    "print(model2.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model2(epochs = 13, learning_rate = 0.001, momentum1 = 0.6, batch_size1 = 60, val_per = 0.15): \n",
    "    model = Sequential() \n",
    "    model.add(Dense(56, input_dim = train_df_scale.shape[1], init = 'uniform'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(56,kernel_initializer = 'uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(52, kernel_initializer = 'uniform', activation = 'tanh'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(26, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    model.add(Dense(1, kernel_initializer= 'normal'))\n",
    "    decay_rate = learning_rate/epochs\n",
    "    sgd = SGD(lr = learning_rate, momentum = momentum1, decay = decay_rate, nesterov = False )\n",
    "    model.compile(loss = 'mae', optimizer = sgd, metric = ['R_square'])\n",
    "    model.fit(train_df_scale, train_y, validation_split = val_per, epochs = epochs, batch_size = batch_size1, verbose = 1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\board\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(56, input_dim=46, kernel_initializer=\"uniform\")`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\board\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2250: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 77189 samples, validate on 13622 samples\n",
      "Epoch 1/13\n",
      "6s - loss: 0.0737 - val_loss: 0.0664\n",
      "Epoch 2/13\n",
      "5s - loss: 0.0697 - val_loss: 0.0659\n",
      "Epoch 3/13\n",
      "5s - loss: 0.0697 - val_loss: 0.0665\n",
      "Epoch 4/13\n",
      "5s - loss: 0.0697 - val_loss: 0.0660\n",
      "Epoch 5/13\n",
      "5s - loss: 0.0697 - val_loss: 0.0663\n",
      "Epoch 6/13\n",
      "4s - loss: 0.0697 - val_loss: 0.0662\n",
      "Epoch 7/13\n",
      "6s - loss: 0.0697 - val_loss: 0.0660\n",
      "Epoch 8/13\n",
      "5s - loss: 0.0697 - val_loss: 0.0665\n",
      "Epoch 9/13\n",
      "5s - loss: 0.0697 - val_loss: 0.0659\n",
      "Epoch 10/13\n",
      "5s - loss: 0.0697 - val_loss: 0.0661\n",
      "Epoch 11/13\n",
      "5s - loss: 0.0696 - val_loss: 0.0667\n",
      "Epoch 12/13\n",
      "4s - loss: 0.0696 - val_loss: 0.0660\n",
      "Epoch 13/13\n",
      "5s - loss: 0.0696 - val_loss: 0.0661\n"
     ]
    }
   ],
   "source": [
    "batch_model = create_model2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\board\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2723: DtypeWarning: Columns (22,32,34,49,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train_df_new = pd.read_csv(\"train_2016.csv\")\n",
    "test = pd.read_csv(\"sample_submission.csv\")\n",
    "prop = pd.read_csv(\"properties_2016.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DF len:  2985217\n",
      "Input DF len:  2985217\n"
     ]
    }
   ],
   "source": [
    "test['parcelid'] = test['ParcelId']\n",
    "df_test = test.merge(prop, on='parcelid', how = 'left') \n",
    "print(\"Test DF len: \" ,len(df_test))\n",
    "print(\"Input DF len: \", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_cols1 = train_cols[1:len(train_cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\board\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3295: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "x_test2 = df_test[train_cols1]\n",
    "test_mean_values = x_test2.mean(axis=0)\n",
    "x_test1 = x_test2.fillna(test_mean_values, inplace=True)\n",
    "x_test = MinMaxScaler().fit_transform(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\board\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2250: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    }
   ],
   "source": [
    "predictions = batch_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"sample_submission.csv\")\n",
    "for c in sub.columns[sub.columns != 'ParcelId']:\n",
    "    sub[c] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('nn_starter2.csv', index=False, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2985217, 7)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
